{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for loading and training models.\n",
    "Furthermore it provides simple documentation for different approaches used for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command below to see command-completion on pressing `TAB`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from matplotlib import pyplot\n",
    "from data_repository import DataRepository\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Datasets by word total:\n",
      "Computer :  58;  Deutschland :  67;  Haben :  71;  Hallo :  62;  Mainz :  67;  Software :  68;  Welt :  68;  du :  70;  ich :  38;  unser :  67;  zeigen :  70;   \n",
      "Amount Datasets by word training:\n",
      "Computer :  35;  Deutschland :  40;  Haben :  42;  Hallo :  37;  Mainz :  40;  Software :  41;  Welt :  41;  du :  42;  ich :  23;  unser :  40;  zeigen :  42;   \n",
      "Amount Datasets by word validiation:\n",
      "Computer :  12;  Deutschland :  13;  Haben :  14;  Hallo :  13;  Mainz :  14;  Software :  13;  Welt :  13;  du :  14;  ich :  8;  unser :  13;  zeigen :  14;   \n",
      "Amount Datasets by word test:\n",
      "Computer :  11;  Deutschland :  14;  Haben :  15;  Hallo :  12;  Mainz :  13;  Software :  14;  Welt :  14;  du :  14;  ich :  7;  unser :  14;  zeigen :  14;   \n",
      "Distribution of data:\n",
      "Amount total: 706\n",
      "Amount training: 423\n",
      "Amount validiation: 141\n",
      "Amount test: 142\n",
      "Tokens:\n",
      "{'computer': 1, 'deutschland': 2, 'du': 3, 'haben': 4, 'hallo': 5, 'ich': 6, 'mainz': 7, 'software': 8, 'unser': 9, 'welt': 10, 'zeigen': 11}\n"
     ]
    }
   ],
   "source": [
    "# Root CSV files directory\n",
    "dirname = \"./data/absolute/2D/\"  \n",
    "\n",
    "repo = DataRepository(dirname, verbose=False)\n",
    "\n",
    "\n",
    "#load all\n",
    "x, y = repo.getDataAndLabels()\n",
    "\n",
    "# Load data and print summary, if desired\n",
    "x_train, x_val, x_test, y_train, y_val, y_test, labels = repo.getForTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.496078  0.242033  0.372475 ...  0.5       0.5       0.5     ]\n",
      " [ 0.495348  0.244273  0.370611 ...  0.262506  0.312994 -0.11808 ]\n",
      " [ 0.497854  0.244501  0.380122 ...  0.5       0.5       0.5     ]\n",
      " ...\n",
      " [ 0.5       0.5       0.5      ...  0.5       0.5       0.5     ]\n",
      " [ 0.5       0.5       0.5      ...  0.5       0.5       0.5     ]\n",
      " [ 0.5       0.5       0.5      ...  0.5       0.5       0.5     ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "def finished(num):\n",
    "    frequency = 2000  # Set Frequency To 2500 Hertz\n",
    "    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "    for i in range(0, num):\n",
    "        winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stage\n",
    "Configure the model and train it.\n",
    "\n",
    "Metrics:\n",
    "<div float=\"right\">\n",
    "    <img src=\"assets/accuracy.png\" width=\"400\"> \n",
    "    <img src=\"assets/precision_recall_formula.png\" width=\"400\">\n",
    "</div>\n",
    "<img src=\"assets/precision_recall.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\"> Hyperparametertuned LSTM </span>\n",
    "##### Here it is necessary to install the Keras-Tuner Module by executing:\n",
    "#####  <span style=\"color:green\"> via Conda:</span>\n",
    "conda install -c conda-forge keras-tuner\n",
    "#####  <span style=\"color:green\"> for pip:</span>\n",
    "pip install keras-tuner\n",
    "\n",
    "Right now there are three different builds we are testing:\n",
    "- classic LSTM\n",
    "- CuDNNLSTM\n",
    "- bidriectional LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from time import time, strftime\n",
    "\n",
    "\n",
    "starttime= strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "LOG_DIR = \"C:\\ML\\Optimization_\"f\"{starttime}\" #<-In Windows below Log_dir Path will maybe be too long for Windows to handle, so use a shorter path like this here\n",
    "#LOG_DIR = \"./Optimization_\"f\"{starttime}\" # LOG_DIR holds json files with information and a model of each single trial\n",
    "\n",
    "def build_model_lstm(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(layers.LSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64), #kerastuner will randomly choose a value for nodes between 128 and 256 in steps of 64\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(layers.LSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True))\n",
    "    \n",
    "    model.add(layers.LSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32)))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adam','RMSprop','SGD']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_model_CuDNNLSTM(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64), #kerastuner will randomly choose a value for nodes between 128 and 256 in steps of 64\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True))\n",
    "    \n",
    "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32)))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adam','RMSprop','SGD']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_model_bdlstm(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(layers.LSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64),\n",
    "                                        return_sequences=True),\n",
    "                                        input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(layers.Bidirectional(layers.LSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True)))\n",
    "    \n",
    "    model.add(layers.Bidirectional(layers.LSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32))))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adamax']),\n",
    "                  metrics=['accuracy']) \n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   <span style=\"color:red\">Necesarry only in case of using Nvidia GPU  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs:\", len(physical_devices)) \n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Keras-Tuner Approaches\n",
    "### 1 - RandomSearch\n",
    "Parameter of variables are ranomly used (number of layers, number of nodes) and \"best\" model is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 95,244\n",
      "Trainable params: 95,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adagrad\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          246528    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          295680    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 64)           65792     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 704,012\n",
      "Trainable params: 704,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "RMSprop\n",
      "\n",
      "Train on 423 samples, validate on 141 samples\n",
      "Epoch 1/200\n",
      "423/423 - 11s - loss: 2.4859 - accuracy: 0.0733 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4349 - val_accuracy: 0.0922 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "423/423 - 0s - loss: 2.4247 - accuracy: 0.0851 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4204 - val_accuracy: 0.0993 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "423/423 - 0s - loss: 2.3889 - accuracy: 0.1206 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3058 - val_accuracy: 0.1702 - val_precision: 0.7500 - val_recall: 0.0213\n",
      "Epoch 4/200\n",
      "423/423 - 0s - loss: 2.2028 - accuracy: 0.1797 - precision: 0.3600 - recall: 0.0213 - val_loss: 1.9667 - val_accuracy: 0.2340 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "423/423 - 0s - loss: 2.0581 - accuracy: 0.1820 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9342 - val_accuracy: 0.2128 - val_precision: 0.4545 - val_recall: 0.0355\n",
      "Epoch 6/200\n",
      "423/423 - 0s - loss: 1.9490 - accuracy: 0.2009 - precision: 0.5000 - recall: 0.0024 - val_loss: 2.2518 - val_accuracy: 0.1844 - val_precision: 0.2131 - val_recall: 0.0922\n",
      "Epoch 7/200\n",
      "423/423 - 0s - loss: 1.9577 - accuracy: 0.2104 - precision: 0.2400 - recall: 0.0142 - val_loss: 2.3797 - val_accuracy: 0.1418 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "423/423 - 0s - loss: 2.1136 - accuracy: 0.1442 - precision: 1.0000 - recall: 0.0024 - val_loss: 1.8635 - val_accuracy: 0.1986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "423/423 - 0s - loss: 1.8799 - accuracy: 0.2459 - precision: 0.6111 - recall: 0.0260 - val_loss: 1.9463 - val_accuracy: 0.1986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      "423/423 - 0s - loss: 1.9723 - accuracy: 0.2151 - precision: 0.1429 - recall: 0.0047 - val_loss: 2.1488 - val_accuracy: 0.1560 - val_precision: 0.5000 - val_recall: 0.0071\n",
      "Epoch 11/200\n",
      "423/423 - 0s - loss: 1.9844 - accuracy: 0.2128 - precision: 0.3750 - recall: 0.0142 - val_loss: 1.8650 - val_accuracy: 0.2199 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "423/423 - 0s - loss: 1.8586 - accuracy: 0.2151 - precision: 0.5500 - recall: 0.0260 - val_loss: 1.8098 - val_accuracy: 0.2199 - val_precision: 0.4706 - val_recall: 0.0567\n",
      "Epoch 13/200\n",
      "423/423 - 0s - loss: 1.8431 - accuracy: 0.2719 - precision: 0.6000 - recall: 0.0567 - val_loss: 2.3170 - val_accuracy: 0.1560 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      "423/423 - 0s - loss: 2.2474 - accuracy: 0.1868 - precision: 0.6000 - recall: 0.0284 - val_loss: 2.4219 - val_accuracy: 0.0922 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      "423/423 - 0s - loss: 2.4124 - accuracy: 0.0922 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3974 - val_accuracy: 0.1418 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      "423/423 - 0s - loss: 2.0099 - accuracy: 0.2270 - precision: 0.5357 - recall: 0.0355 - val_loss: 2.5972 - val_accuracy: 0.0993 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "423/423 - 0s - loss: 1.9206 - accuracy: 0.1986 - precision: 0.7000 - recall: 0.0331 - val_loss: 1.8195 - val_accuracy: 0.2128 - val_precision: 0.4444 - val_recall: 0.0567\n",
      "Epoch 18/200\n",
      "423/423 - 0s - loss: 1.8328 - accuracy: 0.2411 - precision: 0.6000 - recall: 0.0496 - val_loss: 1.8954 - val_accuracy: 0.2340 - val_precision: 0.5000 - val_recall: 0.0071\n",
      "Epoch 19/200\n",
      "423/423 - 0s - loss: 1.8664 - accuracy: 0.2482 - precision: 0.5385 - recall: 0.0496 - val_loss: 1.8106 - val_accuracy: 0.2411 - val_precision: 0.4286 - val_recall: 0.0213\n",
      "Epoch 20/200\n",
      "423/423 - 0s - loss: 1.8290 - accuracy: 0.2742 - precision: 0.6667 - recall: 0.0520 - val_loss: 1.7814 - val_accuracy: 0.2199 - val_precision: 0.4000 - val_recall: 0.0142\n",
      "Epoch 21/200\n",
      "423/423 - 0s - loss: 1.7557 - accuracy: 0.2955 - precision: 0.5897 - recall: 0.0544 - val_loss: 1.7327 - val_accuracy: 0.3050 - val_precision: 0.2941 - val_recall: 0.0355\n",
      "Epoch 22/200\n",
      "423/423 - 0s - loss: 1.8049 - accuracy: 0.2813 - precision: 0.6522 - recall: 0.0709 - val_loss: 1.7243 - val_accuracy: 0.2766 - val_precision: 0.5714 - val_recall: 0.0851\n",
      "Epoch 23/200\n",
      "423/423 - 0s - loss: 1.7709 - accuracy: 0.2861 - precision: 0.6271 - recall: 0.0875 - val_loss: 1.8087 - val_accuracy: 0.2482 - val_precision: 0.7778 - val_recall: 0.0496\n",
      "Epoch 24/200\n",
      "423/423 - 0s - loss: 1.7239 - accuracy: 0.3121 - precision: 0.6604 - recall: 0.0827 - val_loss: 1.7741 - val_accuracy: 0.2553 - val_precision: 0.7143 - val_recall: 0.0709\n",
      "Epoch 25/200\n",
      "423/423 - 0s - loss: 1.7395 - accuracy: 0.3262 - precision: 0.6140 - recall: 0.0827 - val_loss: 1.7010 - val_accuracy: 0.3617 - val_precision: 0.6429 - val_recall: 0.1277\n",
      "Epoch 26/200\n",
      "423/423 - 0s - loss: 1.6911 - accuracy: 0.3428 - precision: 0.6615 - recall: 0.1017 - val_loss: 1.5936 - val_accuracy: 0.3333 - val_precision: 0.6071 - val_recall: 0.1206\n",
      "Epoch 27/200\n",
      "423/423 - 0s - loss: 1.7236 - accuracy: 0.3452 - precision: 0.5679 - recall: 0.1087 - val_loss: 1.6585 - val_accuracy: 0.3475 - val_precision: 0.6522 - val_recall: 0.1064\n",
      "Epoch 28/200\n",
      "423/423 - 0s - loss: 1.6730 - accuracy: 0.3357 - precision: 0.6203 - recall: 0.1158 - val_loss: 2.1739 - val_accuracy: 0.2270 - val_precision: 0.1707 - val_recall: 0.0496\n",
      "Epoch 29/200\n",
      "423/423 - 0s - loss: 1.7962 - accuracy: 0.2979 - precision: 0.5132 - recall: 0.0922 - val_loss: 2.3007 - val_accuracy: 0.1631 - val_precision: 0.1053 - val_recall: 0.0142\n",
      "Epoch 30/200\n",
      "423/423 - 0s - loss: 1.7213 - accuracy: 0.3144 - precision: 0.5556 - recall: 0.0946 - val_loss: 1.6241 - val_accuracy: 0.3333 - val_precision: 0.6316 - val_recall: 0.0851\n",
      "Epoch 31/200\n",
      "423/423 - 0s - loss: 1.6182 - accuracy: 0.3617 - precision: 0.6709 - recall: 0.1253 - val_loss: 1.5749 - val_accuracy: 0.3546 - val_precision: 0.6923 - val_recall: 0.1277\n",
      "Epoch 32/200\n",
      "423/423 - 0s - loss: 1.6267 - accuracy: 0.3641 - precision: 0.6364 - recall: 0.1324 - val_loss: 1.5876 - val_accuracy: 0.3404 - val_precision: 0.4688 - val_recall: 0.1064\n",
      "Epoch 33/200\n",
      "423/423 - 0s - loss: 1.6471 - accuracy: 0.3475 - precision: 0.6214 - recall: 0.1513 - val_loss: 1.6085 - val_accuracy: 0.3191 - val_precision: 0.5429 - val_recall: 0.1348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "423/423 - 0s - loss: 1.5847 - accuracy: 0.3948 - precision: 0.6542 - recall: 0.1655 - val_loss: 1.6289 - val_accuracy: 0.3404 - val_precision: 0.5862 - val_recall: 0.1206\n",
      "Epoch 35/200\n",
      "423/423 - 0s - loss: 1.5862 - accuracy: 0.3593 - precision: 0.6386 - recall: 0.1253 - val_loss: 1.6741 - val_accuracy: 0.3262 - val_precision: 0.6071 - val_recall: 0.1206\n",
      "Epoch 36/200\n",
      "423/423 - 0s - loss: 1.4952 - accuracy: 0.4184 - precision: 0.6765 - recall: 0.1631 - val_loss: 1.4914 - val_accuracy: 0.3759 - val_precision: 0.5641 - val_recall: 0.1560\n",
      "Epoch 37/200\n",
      "423/423 - 0s - loss: 1.4869 - accuracy: 0.4066 - precision: 0.6514 - recall: 0.1678 - val_loss: 1.5015 - val_accuracy: 0.3617 - val_precision: 0.6190 - val_recall: 0.1844\n",
      "Epoch 38/200\n",
      "423/423 - 0s - loss: 1.4608 - accuracy: 0.3972 - precision: 0.6724 - recall: 0.1844 - val_loss: 1.6158 - val_accuracy: 0.3830 - val_precision: 0.6250 - val_recall: 0.1418\n",
      "Epoch 39/200\n",
      "423/423 - 0s - loss: 1.4738 - accuracy: 0.4208 - precision: 0.6508 - recall: 0.1939 - val_loss: 1.3474 - val_accuracy: 0.4255 - val_precision: 0.6047 - val_recall: 0.1844\n",
      "Epoch 40/200\n",
      "423/423 - 0s - loss: 1.5188 - accuracy: 0.3877 - precision: 0.6161 - recall: 0.1631 - val_loss: 1.3293 - val_accuracy: 0.4681 - val_precision: 0.6207 - val_recall: 0.2553\n",
      "Epoch 41/200\n",
      "423/423 - 0s - loss: 1.4984 - accuracy: 0.4326 - precision: 0.6260 - recall: 0.1939 - val_loss: 1.7271 - val_accuracy: 0.3191 - val_precision: 0.5682 - val_recall: 0.1773\n",
      "Epoch 42/200\n",
      "423/423 - 0s - loss: 1.4541 - accuracy: 0.4704 - precision: 0.6325 - recall: 0.2482 - val_loss: 1.4606 - val_accuracy: 0.4468 - val_precision: 0.5000 - val_recall: 0.1631\n",
      "Epoch 43/200\n",
      "423/423 - 0s - loss: 1.3675 - accuracy: 0.4492 - precision: 0.6483 - recall: 0.2222 - val_loss: 1.3421 - val_accuracy: 0.4043 - val_precision: 0.6410 - val_recall: 0.1773\n",
      "Epoch 44/200\n",
      "423/423 - 0s - loss: 1.3271 - accuracy: 0.4374 - precision: 0.6364 - recall: 0.1986 - val_loss: 1.4708 - val_accuracy: 0.4043 - val_precision: 0.5758 - val_recall: 0.1348\n",
      "Epoch 45/200\n",
      "423/423 - 0s - loss: 1.3344 - accuracy: 0.4894 - precision: 0.6714 - recall: 0.2222 - val_loss: 1.3640 - val_accuracy: 0.4326 - val_precision: 0.6585 - val_recall: 0.1915\n",
      "Epoch 46/200\n",
      "423/423 - 0s - loss: 1.2333 - accuracy: 0.5035 - precision: 0.7073 - recall: 0.2742 - val_loss: 1.3030 - val_accuracy: 0.4397 - val_precision: 0.5789 - val_recall: 0.2340\n",
      "Epoch 47/200\n",
      "423/423 - 0s - loss: 1.3136 - accuracy: 0.4846 - precision: 0.7179 - recall: 0.2648 - val_loss: 1.3266 - val_accuracy: 0.5035 - val_precision: 0.6585 - val_recall: 0.1915\n",
      "Epoch 48/200\n",
      "423/423 - 0s - loss: 1.2221 - accuracy: 0.5059 - precision: 0.7384 - recall: 0.3002 - val_loss: 1.3315 - val_accuracy: 0.4326 - val_precision: 0.6122 - val_recall: 0.2128\n",
      "Epoch 49/200\n",
      "423/423 - 0s - loss: 1.2153 - accuracy: 0.5083 - precision: 0.7111 - recall: 0.3026 - val_loss: 1.7223 - val_accuracy: 0.2979 - val_precision: 0.3846 - val_recall: 0.1418\n",
      "Epoch 50/200\n",
      "423/423 - 0s - loss: 1.3635 - accuracy: 0.4492 - precision: 0.6294 - recall: 0.2530 - val_loss: 1.2807 - val_accuracy: 0.4539 - val_precision: 0.7273 - val_recall: 0.2270\n",
      "Epoch 51/200\n",
      "423/423 - 0s - loss: 1.2704 - accuracy: 0.4539 - precision: 0.6959 - recall: 0.2813 - val_loss: 1.1961 - val_accuracy: 0.4894 - val_precision: 0.6667 - val_recall: 0.2553\n",
      "Epoch 52/200\n",
      "423/423 - 0s - loss: 1.1012 - accuracy: 0.5485 - precision: 0.7421 - recall: 0.3333 - val_loss: 1.5866 - val_accuracy: 0.3830 - val_precision: 0.5303 - val_recall: 0.2482\n",
      "Epoch 53/200\n",
      "423/423 - 0s - loss: 1.2358 - accuracy: 0.4965 - precision: 0.6737 - recall: 0.3026 - val_loss: 1.5468 - val_accuracy: 0.3617 - val_precision: 0.4143 - val_recall: 0.2057\n",
      "Epoch 54/200\n",
      "423/423 - 0s - loss: 1.1026 - accuracy: 0.5579 - precision: 0.7236 - recall: 0.3404 - val_loss: 1.1263 - val_accuracy: 0.4823 - val_precision: 0.6143 - val_recall: 0.3050\n",
      "Epoch 55/200\n",
      "423/423 - 0s - loss: 1.1551 - accuracy: 0.5154 - precision: 0.6927 - recall: 0.3570 - val_loss: 1.9479 - val_accuracy: 0.2979 - val_precision: 0.3478 - val_recall: 0.1702\n",
      "Epoch 56/200\n",
      "423/423 - 0s - loss: 1.2061 - accuracy: 0.5272 - precision: 0.6453 - recall: 0.3097 - val_loss: 1.3702 - val_accuracy: 0.4255 - val_precision: 0.5410 - val_recall: 0.2340\n",
      "Epoch 57/200\n",
      "423/423 - 0s - loss: 1.0903 - accuracy: 0.5579 - precision: 0.7756 - recall: 0.3759 - val_loss: 1.2586 - val_accuracy: 0.5248 - val_precision: 0.5943 - val_recall: 0.4468\n",
      "Epoch 58/200\n",
      "423/423 - 0s - loss: 1.1806 - accuracy: 0.5508 - precision: 0.6735 - recall: 0.3901 - val_loss: 1.6678 - val_accuracy: 0.3759 - val_precision: 0.4773 - val_recall: 0.2979\n",
      "Epoch 59/200\n",
      "423/423 - 0s - loss: 1.1843 - accuracy: 0.5461 - precision: 0.7168 - recall: 0.3830 - val_loss: 1.0458 - val_accuracy: 0.6170 - val_precision: 0.7059 - val_recall: 0.4255\n",
      "Epoch 60/200\n",
      "423/423 - 0s - loss: 0.9409 - accuracy: 0.6359 - precision: 0.8000 - recall: 0.4634 - val_loss: 1.3333 - val_accuracy: 0.4965 - val_precision: 0.6824 - val_recall: 0.4113\n",
      "Epoch 61/200\n",
      "423/423 - 0s - loss: 0.9492 - accuracy: 0.6312 - precision: 0.7741 - recall: 0.4941 - val_loss: 1.2860 - val_accuracy: 0.5390 - val_precision: 0.7000 - val_recall: 0.3475\n",
      "Epoch 62/200\n",
      "423/423 - 0s - loss: 1.0492 - accuracy: 0.5745 - precision: 0.7143 - recall: 0.4492 - val_loss: 1.9371 - val_accuracy: 0.3617 - val_precision: 0.5294 - val_recall: 0.1915\n",
      "Epoch 63/200\n",
      "423/423 - 0s - loss: 1.0712 - accuracy: 0.5745 - precision: 0.7490 - recall: 0.4374 - val_loss: 1.0456 - val_accuracy: 0.5674 - val_precision: 0.6824 - val_recall: 0.4113\n",
      "Epoch 64/200\n",
      "423/423 - 0s - loss: 1.1452 - accuracy: 0.5721 - precision: 0.6800 - recall: 0.4421 - val_loss: 1.6444 - val_accuracy: 0.5106 - val_precision: 0.6582 - val_recall: 0.3688\n",
      "Epoch 65/200\n",
      "423/423 - 0s - loss: 0.9961 - accuracy: 0.6265 - precision: 0.7795 - recall: 0.4846 - val_loss: 1.0074 - val_accuracy: 0.5390 - val_precision: 0.6211 - val_recall: 0.4184\n",
      "Epoch 66/200\n",
      "423/423 - 0s - loss: 0.9407 - accuracy: 0.6548 - precision: 0.7406 - recall: 0.5130 - val_loss: 1.0367 - val_accuracy: 0.5957 - val_precision: 0.7901 - val_recall: 0.4539\n",
      "Epoch 67/200\n",
      "423/423 - 0s - loss: 0.9482 - accuracy: 0.6336 - precision: 0.7823 - recall: 0.5012 - val_loss: 0.9795 - val_accuracy: 0.6312 - val_precision: 0.7527 - val_recall: 0.4965\n",
      "Epoch 68/200\n",
      "423/423 - 0s - loss: 1.0337 - accuracy: 0.6217 - precision: 0.7067 - recall: 0.5012 - val_loss: 1.1483 - val_accuracy: 0.5532 - val_precision: 0.6344 - val_recall: 0.4184\n",
      "Epoch 69/200\n",
      "423/423 - 0s - loss: 0.8553 - accuracy: 0.6690 - precision: 0.7700 - recall: 0.5225 - val_loss: 1.2364 - val_accuracy: 0.5319 - val_precision: 0.6933 - val_recall: 0.3688\n",
      "Epoch 70/200\n",
      "423/423 - 0s - loss: 1.0086 - accuracy: 0.5816 - precision: 0.7538 - recall: 0.4634 - val_loss: 1.0778 - val_accuracy: 0.5603 - val_precision: 0.6699 - val_recall: 0.4894\n",
      "Epoch 71/200\n",
      "423/423 - 0s - loss: 0.9076 - accuracy: 0.6312 - precision: 0.7406 - recall: 0.5130 - val_loss: 1.0486 - val_accuracy: 0.6312 - val_precision: 0.7283 - val_recall: 0.4752\n",
      "Epoch 72/200\n",
      "423/423 - 0s - loss: 0.8525 - accuracy: 0.6856 - precision: 0.7987 - recall: 0.5910 - val_loss: 1.4125 - val_accuracy: 0.5248 - val_precision: 0.6818 - val_recall: 0.4255\n",
      "Epoch 73/200\n",
      "423/423 - 0s - loss: 0.8718 - accuracy: 0.6714 - precision: 0.7831 - recall: 0.5461 - val_loss: 1.1530 - val_accuracy: 0.5674 - val_precision: 0.6556 - val_recall: 0.4184\n",
      "Epoch 74/200\n",
      "423/423 - 0s - loss: 0.7666 - accuracy: 0.7069 - precision: 0.8231 - recall: 0.5721 - val_loss: 0.9519 - val_accuracy: 0.6383 - val_precision: 0.7009 - val_recall: 0.5319\n",
      "Epoch 75/200\n",
      "423/423 - 0s - loss: 0.7927 - accuracy: 0.6832 - precision: 0.8203 - recall: 0.5721 - val_loss: 0.8981 - val_accuracy: 0.6667 - val_precision: 0.8085 - val_recall: 0.5390\n",
      "Epoch 76/200\n",
      "423/423 - 0s - loss: 0.8118 - accuracy: 0.6856 - precision: 0.7746 - recall: 0.5768 - val_loss: 0.8524 - val_accuracy: 0.6738 - val_precision: 0.7527 - val_recall: 0.4965\n",
      "Epoch 77/200\n",
      "423/423 - 0s - loss: 0.7444 - accuracy: 0.7139 - precision: 0.8215 - recall: 0.5768 - val_loss: 0.8418 - val_accuracy: 0.6809 - val_precision: 0.7624 - val_recall: 0.5461\n",
      "Epoch 78/200\n",
      "423/423 - 0s - loss: 0.7021 - accuracy: 0.7329 - precision: 0.8179 - recall: 0.6478 - val_loss: 1.0383 - val_accuracy: 0.5816 - val_precision: 0.6961 - val_recall: 0.5035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "423/423 - 0s - loss: 0.8103 - accuracy: 0.6974 - precision: 0.8097 - recall: 0.5934 - val_loss: 1.1119 - val_accuracy: 0.6028 - val_precision: 0.6531 - val_recall: 0.4539\n",
      "Epoch 80/200\n",
      "423/423 - 0s - loss: 0.8083 - accuracy: 0.7045 - precision: 0.8176 - recall: 0.5934 - val_loss: 0.7714 - val_accuracy: 0.7021 - val_precision: 0.7944 - val_recall: 0.6028\n",
      "Epoch 81/200\n",
      "423/423 - 0s - loss: 0.7062 - accuracy: 0.7139 - precision: 0.8125 - recall: 0.6147 - val_loss: 0.8446 - val_accuracy: 0.6454 - val_precision: 0.7843 - val_recall: 0.5674\n",
      "Epoch 82/200\n",
      "423/423 - 0s - loss: 0.6668 - accuracy: 0.7305 - precision: 0.8249 - recall: 0.6572 - val_loss: 1.4265 - val_accuracy: 0.5248 - val_precision: 0.5816 - val_recall: 0.4043\n",
      "Epoch 83/200\n",
      "423/423 - 0s - loss: 0.9742 - accuracy: 0.6785 - precision: 0.7855 - recall: 0.5887 - val_loss: 0.8070 - val_accuracy: 0.7163 - val_precision: 0.8211 - val_recall: 0.5532\n",
      "Epoch 84/200\n",
      "423/423 - 0s - loss: 0.6910 - accuracy: 0.7258 - precision: 0.8548 - recall: 0.6265 - val_loss: 0.9619 - val_accuracy: 0.7163 - val_precision: 0.8444 - val_recall: 0.5390\n",
      "Epoch 85/200\n",
      "423/423 - 0s - loss: 0.7436 - accuracy: 0.7258 - precision: 0.8377 - recall: 0.5981 - val_loss: 1.6108 - val_accuracy: 0.5319 - val_precision: 0.6068 - val_recall: 0.5035\n",
      "Epoch 86/200\n",
      "423/423 - 0s - loss: 0.7138 - accuracy: 0.7116 - precision: 0.8055 - recall: 0.6265 - val_loss: 0.9757 - val_accuracy: 0.6738 - val_precision: 0.7935 - val_recall: 0.5177\n",
      "Epoch 87/200\n",
      "423/423 - 0s - loss: 0.7581 - accuracy: 0.7069 - precision: 0.8355 - recall: 0.6005 - val_loss: 0.8452 - val_accuracy: 0.7021 - val_precision: 0.7436 - val_recall: 0.6170\n",
      "Epoch 88/200\n",
      "423/423 - 0s - loss: 0.7706 - accuracy: 0.6974 - precision: 0.7911 - recall: 0.5910 - val_loss: 0.7689 - val_accuracy: 0.7305 - val_precision: 0.8280 - val_recall: 0.5461\n",
      "Epoch 89/200\n",
      "423/423 - 0s - loss: 0.6648 - accuracy: 0.7660 - precision: 0.8375 - recall: 0.6336 - val_loss: 0.7187 - val_accuracy: 0.7163 - val_precision: 0.7787 - val_recall: 0.6738\n",
      "Epoch 90/200\n",
      "423/423 - 0s - loss: 0.6431 - accuracy: 0.7589 - precision: 0.8212 - recall: 0.6950 - val_loss: 1.0077 - val_accuracy: 0.6809 - val_precision: 0.7120 - val_recall: 0.6312\n",
      "Epoch 91/200\n",
      "423/423 - 0s - loss: 0.6052 - accuracy: 0.7730 - precision: 0.8260 - recall: 0.7069 - val_loss: 0.7521 - val_accuracy: 0.7447 - val_precision: 0.8083 - val_recall: 0.6879\n",
      "Epoch 92/200\n",
      "423/423 - 0s - loss: 0.5865 - accuracy: 0.7707 - precision: 0.8157 - recall: 0.7116 - val_loss: 0.7843 - val_accuracy: 0.7092 - val_precision: 0.8370 - val_recall: 0.5461\n",
      "Epoch 93/200\n",
      "423/423 - 0s - loss: 0.6064 - accuracy: 0.7612 - precision: 0.8516 - recall: 0.6785 - val_loss: 0.9710 - val_accuracy: 0.6879 - val_precision: 0.7455 - val_recall: 0.5816\n",
      "Epoch 94/200\n",
      "423/423 - 0s - loss: 0.6178 - accuracy: 0.7589 - precision: 0.8533 - recall: 0.6738 - val_loss: 0.8532 - val_accuracy: 0.6596 - val_precision: 0.7333 - val_recall: 0.6241\n",
      "Epoch 95/200\n",
      "423/423 - 0s - loss: 0.5940 - accuracy: 0.7683 - precision: 0.8235 - recall: 0.6950 - val_loss: 0.6543 - val_accuracy: 0.7660 - val_precision: 0.8713 - val_recall: 0.6241\n",
      "Epoch 96/200\n",
      "423/423 - 0s - loss: 0.5316 - accuracy: 0.7967 - precision: 0.8682 - recall: 0.7163 - val_loss: 0.7568 - val_accuracy: 0.7163 - val_precision: 0.8198 - val_recall: 0.6454\n",
      "Epoch 97/200\n",
      "423/423 - 0s - loss: 0.5965 - accuracy: 0.7825 - precision: 0.8453 - recall: 0.7234 - val_loss: 0.8723 - val_accuracy: 0.7234 - val_precision: 0.7521 - val_recall: 0.6454\n",
      "Epoch 98/200\n",
      "423/423 - 0s - loss: 0.5191 - accuracy: 0.8085 - precision: 0.8623 - recall: 0.7400 - val_loss: 0.7889 - val_accuracy: 0.6950 - val_precision: 0.7273 - val_recall: 0.6809\n",
      "Epoch 99/200\n",
      "423/423 - 0s - loss: 0.5551 - accuracy: 0.7991 - precision: 0.8533 - recall: 0.7565 - val_loss: 0.6926 - val_accuracy: 0.7589 - val_precision: 0.7969 - val_recall: 0.7234\n",
      "Epoch 100/200\n",
      "423/423 - 0s - loss: 0.6272 - accuracy: 0.7754 - precision: 0.8133 - recall: 0.7210 - val_loss: 0.7227 - val_accuracy: 0.7518 - val_precision: 0.8598 - val_recall: 0.6525\n",
      "Epoch 101/200\n",
      "423/423 - 0s - loss: 0.5424 - accuracy: 0.8014 - precision: 0.8747 - recall: 0.7423 - val_loss: 0.8811 - val_accuracy: 0.6879 - val_precision: 0.7818 - val_recall: 0.6099\n",
      "Epoch 102/200\n",
      "423/423 - 0s - loss: 0.4727 - accuracy: 0.8251 - precision: 0.9176 - recall: 0.7376 - val_loss: 0.6777 - val_accuracy: 0.7447 - val_precision: 0.7481 - val_recall: 0.7163\n",
      "Epoch 103/200\n",
      "423/423 - 0s - loss: 0.5546 - accuracy: 0.7991 - precision: 0.8449 - recall: 0.7470 - val_loss: 0.8196 - val_accuracy: 0.7447 - val_precision: 0.7846 - val_recall: 0.7234\n",
      "Epoch 104/200\n",
      "423/423 - 0s - loss: 0.5315 - accuracy: 0.8061 - precision: 0.8425 - recall: 0.7589 - val_loss: 0.8085 - val_accuracy: 0.7163 - val_precision: 0.7876 - val_recall: 0.6312\n",
      "Epoch 105/200\n",
      "423/423 - 0s - loss: 0.4292 - accuracy: 0.8156 - precision: 0.8880 - recall: 0.7683 - val_loss: 0.8783 - val_accuracy: 0.7234 - val_precision: 0.7353 - val_recall: 0.7092\n",
      "Epoch 106/200\n",
      "423/423 - 0s - loss: 0.4702 - accuracy: 0.8180 - precision: 0.8679 - recall: 0.7920 - val_loss: 1.1944 - val_accuracy: 0.5887 - val_precision: 0.6803 - val_recall: 0.5887\n",
      "Epoch 107/200\n",
      "423/423 - 0s - loss: 0.4392 - accuracy: 0.8463 - precision: 0.8892 - recall: 0.7967 - val_loss: 0.7389 - val_accuracy: 0.7234 - val_precision: 0.8000 - val_recall: 0.7092\n",
      "Epoch 108/200\n",
      "423/423 - 0s - loss: 0.5056 - accuracy: 0.8463 - precision: 0.8718 - recall: 0.8038 - val_loss: 0.7054 - val_accuracy: 0.7730 - val_precision: 0.7754 - val_recall: 0.7589\n",
      "Epoch 109/200\n",
      "423/423 - 0s - loss: 0.4025 - accuracy: 0.8700 - precision: 0.8780 - recall: 0.8511 - val_loss: 0.8352 - val_accuracy: 0.7376 - val_precision: 0.7917 - val_recall: 0.6738\n",
      "Epoch 110/200\n",
      "423/423 - 0s - loss: 0.5206 - accuracy: 0.8345 - precision: 0.8557 - recall: 0.7991 - val_loss: 0.5991 - val_accuracy: 0.7872 - val_precision: 0.8333 - val_recall: 0.7447\n",
      "Epoch 111/200\n",
      "423/423 - 0s - loss: 0.3313 - accuracy: 0.8842 - precision: 0.9012 - recall: 0.8629 - val_loss: 0.8526 - val_accuracy: 0.7305 - val_precision: 0.7519 - val_recall: 0.7092\n",
      "Epoch 112/200\n",
      "423/423 - 0s - loss: 0.5086 - accuracy: 0.8227 - precision: 0.8450 - recall: 0.7991 - val_loss: 0.7744 - val_accuracy: 0.7872 - val_precision: 0.8182 - val_recall: 0.7660\n",
      "Epoch 113/200\n",
      "423/423 - 0s - loss: 0.5062 - accuracy: 0.8345 - precision: 0.8473 - recall: 0.8132 - val_loss: 0.9909 - val_accuracy: 0.6596 - val_precision: 0.7000 - val_recall: 0.6454\n",
      "Epoch 114/200\n",
      "423/423 - 0s - loss: 0.3815 - accuracy: 0.8676 - precision: 0.9010 - recall: 0.8392 - val_loss: 1.0534 - val_accuracy: 0.6667 - val_precision: 0.7045 - val_recall: 0.6596\n",
      "Epoch 115/200\n",
      "423/423 - 0s - loss: 0.4815 - accuracy: 0.8534 - precision: 0.8662 - recall: 0.8416 - val_loss: 0.7326 - val_accuracy: 0.7801 - val_precision: 0.7956 - val_recall: 0.7730\n",
      "Epoch 116/200\n",
      "423/423 - 0s - loss: 0.4822 - accuracy: 0.8487 - precision: 0.8680 - recall: 0.8392 - val_loss: 0.8167 - val_accuracy: 0.7305 - val_precision: 0.7857 - val_recall: 0.7021\n",
      "Epoch 117/200\n",
      "423/423 - 0s - loss: 0.3628 - accuracy: 0.8913 - precision: 0.9007 - recall: 0.8794 - val_loss: 0.6834 - val_accuracy: 0.7730 - val_precision: 0.7955 - val_recall: 0.7447\n",
      "Epoch 118/200\n",
      "423/423 - 0s - loss: 0.4714 - accuracy: 0.8156 - precision: 0.8835 - recall: 0.7707 - val_loss: 0.6741 - val_accuracy: 0.7447 - val_precision: 0.8047 - val_recall: 0.7305\n",
      "Epoch 119/200\n",
      "423/423 - 0s - loss: 0.4028 - accuracy: 0.8582 - precision: 0.8738 - recall: 0.8345 - val_loss: 0.6926 - val_accuracy: 0.7801 - val_precision: 0.8110 - val_recall: 0.7305\n",
      "Epoch 120/200\n",
      "423/423 - 0s - loss: 0.3696 - accuracy: 0.8889 - precision: 0.9059 - recall: 0.8652 - val_loss: 0.5882 - val_accuracy: 0.8085 - val_precision: 0.8261 - val_recall: 0.8085\n",
      "Epoch 121/200\n",
      "423/423 - 0s - loss: 0.3023 - accuracy: 0.8960 - precision: 0.9005 - recall: 0.8771 - val_loss: 0.4431 - val_accuracy: 0.8582 - val_precision: 0.8741 - val_recall: 0.8369\n",
      "Epoch 122/200\n",
      "423/423 - 0s - loss: 0.4177 - accuracy: 0.8605 - precision: 0.8786 - recall: 0.8558 - val_loss: 0.6780 - val_accuracy: 0.7872 - val_precision: 0.7956 - val_recall: 0.7730\n",
      "Epoch 123/200\n",
      "423/423 - 0s - loss: 0.3831 - accuracy: 0.8960 - precision: 0.9080 - recall: 0.8865 - val_loss: 0.8972 - val_accuracy: 0.6879 - val_precision: 0.7442 - val_recall: 0.6809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "423/423 - 0s - loss: 0.6498 - accuracy: 0.7825 - precision: 0.8046 - recall: 0.7400 - val_loss: 0.7967 - val_accuracy: 0.7305 - val_precision: 0.7557 - val_recall: 0.7021\n",
      "Epoch 125/200\n",
      "423/423 - 0s - loss: 0.4095 - accuracy: 0.8582 - precision: 0.8942 - recall: 0.8392 - val_loss: 0.4824 - val_accuracy: 0.8723 - val_precision: 0.8846 - val_recall: 0.8156\n",
      "Epoch 126/200\n",
      "423/423 - 0s - loss: 0.3478 - accuracy: 0.9196 - precision: 0.9332 - recall: 0.8913 - val_loss: 0.5964 - val_accuracy: 0.8156 - val_precision: 0.8261 - val_recall: 0.8085\n",
      "Epoch 127/200\n",
      "423/423 - 0s - loss: 0.2365 - accuracy: 0.9338 - precision: 0.9379 - recall: 0.9291 - val_loss: 0.6499 - val_accuracy: 0.8440 - val_precision: 0.8561 - val_recall: 0.8440\n",
      "Epoch 128/200\n",
      "423/423 - 0s - loss: 0.2280 - accuracy: 0.9291 - precision: 0.9444 - recall: 0.9243 - val_loss: 0.8656 - val_accuracy: 0.7447 - val_precision: 0.7574 - val_recall: 0.7305\n",
      "Epoch 129/200\n",
      "423/423 - 0s - loss: 0.4064 - accuracy: 0.8794 - precision: 0.8922 - recall: 0.8605 - val_loss: 0.4872 - val_accuracy: 0.8723 - val_precision: 0.8889 - val_recall: 0.8511\n",
      "Epoch 130/200\n",
      "423/423 - 0s - loss: 0.2556 - accuracy: 0.9267 - precision: 0.9351 - recall: 0.9196 - val_loss: 0.6389 - val_accuracy: 0.8085 - val_precision: 0.8071 - val_recall: 0.8014\n",
      "Epoch 131/200\n",
      "423/423 - 0s - loss: 0.2383 - accuracy: 0.9078 - precision: 0.9314 - recall: 0.8983 - val_loss: 0.4921 - val_accuracy: 0.8511 - val_precision: 0.8623 - val_recall: 0.8440\n",
      "Epoch 132/200\n",
      "423/423 - 0s - loss: 0.2461 - accuracy: 0.9291 - precision: 0.9420 - recall: 0.9220 - val_loss: 0.5890 - val_accuracy: 0.8227 - val_precision: 0.8406 - val_recall: 0.8227\n",
      "Epoch 133/200\n",
      "423/423 - 0s - loss: 0.1332 - accuracy: 0.9622 - precision: 0.9665 - recall: 0.9551 - val_loss: 0.4611 - val_accuracy: 0.8794 - val_precision: 0.8841 - val_recall: 0.8652\n",
      "Epoch 134/200\n",
      "423/423 - 0s - loss: 0.1041 - accuracy: 0.9693 - precision: 0.9738 - recall: 0.9669 - val_loss: 0.7634 - val_accuracy: 0.8014 - val_precision: 0.7986 - val_recall: 0.7872\n",
      "Epoch 135/200\n",
      "423/423 - 0s - loss: 0.2099 - accuracy: 0.9433 - precision: 0.9447 - recall: 0.9291 - val_loss: 1.1499 - val_accuracy: 0.7447 - val_precision: 0.7518 - val_recall: 0.7305\n",
      "Epoch 136/200\n",
      "423/423 - 0s - loss: 0.2857 - accuracy: 0.9149 - precision: 0.9301 - recall: 0.9125 - val_loss: 0.6148 - val_accuracy: 0.8582 - val_precision: 0.8571 - val_recall: 0.8511\n",
      "Epoch 137/200\n",
      "423/423 - 0s - loss: 0.2176 - accuracy: 0.9409 - precision: 0.9493 - recall: 0.9291 - val_loss: 0.9110 - val_accuracy: 0.7801 - val_precision: 0.7826 - val_recall: 0.7660\n",
      "Epoch 138/200\n",
      "423/423 - 0s - loss: 0.3282 - accuracy: 0.9007 - precision: 0.9242 - recall: 0.8936 - val_loss: 0.7452 - val_accuracy: 0.7801 - val_precision: 0.8120 - val_recall: 0.7660\n",
      "Epoch 139/200\n",
      "423/423 - 0s - loss: 0.2196 - accuracy: 0.9385 - precision: 0.9475 - recall: 0.9385 - val_loss: 0.7894 - val_accuracy: 0.7872 - val_precision: 0.8209 - val_recall: 0.7801\n",
      "Epoch 140/200\n",
      "423/423 - 0s - loss: 0.1465 - accuracy: 0.9645 - precision: 0.9668 - recall: 0.9645 - val_loss: 0.8012 - val_accuracy: 0.8014 - val_precision: 0.8071 - val_recall: 0.8014\n",
      "Epoch 141/200\n",
      "423/423 - 0s - loss: 0.1264 - accuracy: 0.9669 - precision: 0.9690 - recall: 0.9622 - val_loss: 0.7322 - val_accuracy: 0.8369 - val_precision: 0.8357 - val_recall: 0.8298\n",
      "Epoch 142/200\n",
      "423/423 - 0s - loss: 0.2182 - accuracy: 0.9362 - precision: 0.9402 - recall: 0.9291 - val_loss: 0.7121 - val_accuracy: 0.8156 - val_precision: 0.8248 - val_recall: 0.8014\n",
      "Epoch 143/200\n",
      "423/423 - 0s - loss: 0.2870 - accuracy: 0.9102 - precision: 0.9251 - recall: 0.9054 - val_loss: 0.5478 - val_accuracy: 0.8652 - val_precision: 0.8705 - val_recall: 0.8582\n",
      "Epoch 144/200\n",
      "423/423 - 0s - loss: 0.1940 - accuracy: 0.9456 - precision: 0.9545 - recall: 0.9433 - val_loss: 0.5411 - val_accuracy: 0.8369 - val_precision: 0.8551 - val_recall: 0.8369\n",
      "Epoch 145/200\n",
      "423/423 - 0s - loss: 0.1331 - accuracy: 0.9598 - precision: 0.9643 - recall: 0.9574 - val_loss: 0.5533 - val_accuracy: 0.8723 - val_precision: 0.8723 - val_recall: 0.8723\n",
      "Epoch 146/200\n",
      "423/423 - 0s - loss: 0.2486 - accuracy: 0.9338 - precision: 0.9467 - recall: 0.9243 - val_loss: 1.3077 - val_accuracy: 0.7163 - val_precision: 0.7174 - val_recall: 0.7021\n",
      "Epoch 147/200\n",
      "423/423 - 0s - loss: 0.4285 - accuracy: 0.8983 - precision: 0.9155 - recall: 0.8960 - val_loss: 0.6497 - val_accuracy: 0.8440 - val_precision: 0.8540 - val_recall: 0.8298\n",
      "Epoch 148/200\n",
      "423/423 - 0s - loss: 0.0823 - accuracy: 0.9740 - precision: 0.9740 - recall: 0.9740 - val_loss: 0.5036 - val_accuracy: 0.8723 - val_precision: 0.8714 - val_recall: 0.8652\n",
      "Epoch 149/200\n",
      "423/423 - 0s - loss: 0.2128 - accuracy: 0.9504 - precision: 0.9525 - recall: 0.9480 - val_loss: 1.1655 - val_accuracy: 0.7447 - val_precision: 0.7429 - val_recall: 0.7376\n",
      "Epoch 150/200\n",
      "423/423 - 0s - loss: 0.2646 - accuracy: 0.9314 - precision: 0.9422 - recall: 0.9243 - val_loss: 0.4344 - val_accuracy: 0.8865 - val_precision: 0.8986 - val_recall: 0.8794\n",
      "Epoch 151/200\n",
      "423/423 - 0s - loss: 0.0917 - accuracy: 0.9811 - precision: 0.9810 - recall: 0.9764 - val_loss: 0.4483 - val_accuracy: 0.8652 - val_precision: 0.8759 - val_recall: 0.8511\n",
      "Epoch 152/200\n",
      "423/423 - 0s - loss: 0.0249 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.4868 - val_accuracy: 0.8865 - val_precision: 0.8986 - val_recall: 0.8794\n",
      "Epoch 153/200\n",
      "423/423 - 0s - loss: 0.1529 - accuracy: 0.9574 - precision: 0.9573 - recall: 0.9551 - val_loss: 0.6362 - val_accuracy: 0.8794 - val_precision: 0.8794 - val_recall: 0.8794\n",
      "Epoch 154/200\n",
      "423/423 - 0s - loss: 0.2972 - accuracy: 0.9149 - precision: 0.9236 - recall: 0.9149 - val_loss: 0.7854 - val_accuracy: 0.8227 - val_precision: 0.8188 - val_recall: 0.8014\n",
      "Epoch 155/200\n",
      "423/423 - 0s - loss: 0.2362 - accuracy: 0.9385 - precision: 0.9430 - recall: 0.9385 - val_loss: 0.7002 - val_accuracy: 0.8582 - val_precision: 0.8705 - val_recall: 0.8582\n",
      "Epoch 156/200\n",
      "423/423 - 0s - loss: 0.2556 - accuracy: 0.9196 - precision: 0.9282 - recall: 0.9173 - val_loss: 0.6592 - val_accuracy: 0.8511 - val_precision: 0.8561 - val_recall: 0.8440\n",
      "Epoch 157/200\n",
      "423/423 - 0s - loss: 0.1224 - accuracy: 0.9669 - precision: 0.9692 - recall: 0.9669 - val_loss: 0.5991 - val_accuracy: 0.8582 - val_precision: 0.8643 - val_recall: 0.8582\n",
      "Epoch 158/200\n",
      "423/423 - 0s - loss: 0.1481 - accuracy: 0.9598 - precision: 0.9620 - recall: 0.9574 - val_loss: 0.5505 - val_accuracy: 0.8723 - val_precision: 0.8723 - val_recall: 0.8723\n",
      "Epoch 159/200\n",
      "423/423 - 0s - loss: 0.1126 - accuracy: 0.9716 - precision: 0.9715 - recall: 0.9669 - val_loss: 0.8739 - val_accuracy: 0.7872 - val_precision: 0.7971 - val_recall: 0.7801\n",
      "Epoch 160/200\n",
      "423/423 - 0s - loss: 0.3477 - accuracy: 0.9173 - precision: 0.9190 - recall: 0.9125 - val_loss: 0.8247 - val_accuracy: 0.8014 - val_precision: 0.8071 - val_recall: 0.8014\n",
      "Epoch 161/200\n",
      "423/423 - 0s - loss: 0.1753 - accuracy: 0.9504 - precision: 0.9570 - recall: 0.9480 - val_loss: 0.7040 - val_accuracy: 0.8440 - val_precision: 0.8489 - val_recall: 0.8369\n",
      "Epoch 162/200\n",
      "423/423 - 0s - loss: 0.1791 - accuracy: 0.9527 - precision: 0.9638 - recall: 0.9433 - val_loss: 0.8624 - val_accuracy: 0.7943 - val_precision: 0.8029 - val_recall: 0.7801\n",
      "Epoch 163/200\n",
      "423/423 - 1s - loss: 0.1464 - accuracy: 0.9622 - precision: 0.9667 - recall: 0.9598 - val_loss: 0.7481 - val_accuracy: 0.8085 - val_precision: 0.8201 - val_recall: 0.8085\n",
      "Epoch 164/200\n",
      "423/423 - 1s - loss: 0.1597 - accuracy: 0.9527 - precision: 0.9572 - recall: 0.9527 - val_loss: 0.7254 - val_accuracy: 0.8014 - val_precision: 0.8248 - val_recall: 0.8014\n",
      "Epoch 165/200\n",
      "423/423 - 0s - loss: 0.1007 - accuracy: 0.9622 - precision: 0.9713 - recall: 0.9598 - val_loss: 1.0975 - val_accuracy: 0.7376 - val_precision: 0.7591 - val_recall: 0.7376\n",
      "Epoch 166/200\n",
      "423/423 - 0s - loss: 0.2090 - accuracy: 0.9385 - precision: 0.9406 - recall: 0.9362 - val_loss: 0.5480 - val_accuracy: 0.8582 - val_precision: 0.8759 - val_recall: 0.8511\n",
      "Epoch 167/200\n",
      "423/423 - 0s - loss: 0.1130 - accuracy: 0.9693 - precision: 0.9692 - recall: 0.9669 - val_loss: 0.7610 - val_accuracy: 0.8227 - val_precision: 0.8273 - val_recall: 0.8156\n",
      "Epoch 168/200\n",
      "423/423 - 0s - loss: 0.1090 - accuracy: 0.9622 - precision: 0.9667 - recall: 0.9622 - val_loss: 0.5851 - val_accuracy: 0.8298 - val_precision: 0.8417 - val_recall: 0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "423/423 - 0s - loss: 0.1161 - accuracy: 0.9693 - precision: 0.9691 - recall: 0.9645 - val_loss: 0.6654 - val_accuracy: 0.8369 - val_precision: 0.8357 - val_recall: 0.8298\n",
      "Epoch 170/200\n",
      "423/423 - 0s - loss: 0.2214 - accuracy: 0.9480 - precision: 0.9477 - recall: 0.9433 - val_loss: 0.6683 - val_accuracy: 0.8652 - val_precision: 0.8643 - val_recall: 0.8582\n",
      "Epoch 171/200\n",
      "423/423 - 0s - loss: 0.0582 - accuracy: 0.9811 - precision: 0.9857 - recall: 0.9811 - val_loss: 0.8178 - val_accuracy: 0.7730 - val_precision: 0.7770 - val_recall: 0.7660\n",
      "Epoch 172/200\n",
      "423/423 - 0s - loss: 0.1375 - accuracy: 0.9693 - precision: 0.9714 - recall: 0.9622 - val_loss: 0.5702 - val_accuracy: 0.8582 - val_precision: 0.8759 - val_recall: 0.8511\n",
      "Epoch 173/200\n",
      "423/423 - 0s - loss: 0.1696 - accuracy: 0.9574 - precision: 0.9596 - recall: 0.9551 - val_loss: 0.7076 - val_accuracy: 0.8227 - val_precision: 0.8273 - val_recall: 0.8156\n",
      "Epoch 174/200\n",
      "423/423 - 0s - loss: 0.0977 - accuracy: 0.9716 - precision: 0.9739 - recall: 0.9693 - val_loss: 0.5031 - val_accuracy: 0.8936 - val_precision: 0.9000 - val_recall: 0.8936\n",
      "Epoch 175/200\n",
      "423/423 - 0s - loss: 0.0336 - accuracy: 0.9953 - precision: 0.9976 - recall: 0.9953 - val_loss: 0.4546 - val_accuracy: 0.8865 - val_precision: 0.8921 - val_recall: 0.8794\n",
      "Epoch 176/200\n",
      "423/423 - 0s - loss: 0.0184 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9929 - val_loss: 0.6063 - val_accuracy: 0.8652 - val_precision: 0.8777 - val_recall: 0.8652\n",
      "Epoch 177/200\n",
      "423/423 - 0s - loss: 0.1547 - accuracy: 0.9693 - precision: 0.9715 - recall: 0.9669 - val_loss: 0.7140 - val_accuracy: 0.8227 - val_precision: 0.8345 - val_recall: 0.8227\n",
      "Epoch 178/200\n",
      "423/423 - 0s - loss: 0.0885 - accuracy: 0.9811 - precision: 0.9857 - recall: 0.9787 - val_loss: 0.6469 - val_accuracy: 0.8582 - val_precision: 0.8582 - val_recall: 0.8582\n",
      "Epoch 179/200\n",
      "423/423 - 0s - loss: 0.3690 - accuracy: 0.9220 - precision: 0.9308 - recall: 0.9220 - val_loss: 0.8373 - val_accuracy: 0.8156 - val_precision: 0.8214 - val_recall: 0.8156\n",
      "Epoch 180/200\n",
      "423/423 - 0s - loss: 0.1592 - accuracy: 0.9504 - precision: 0.9499 - recall: 0.9409 - val_loss: 0.6164 - val_accuracy: 0.8652 - val_precision: 0.8768 - val_recall: 0.8582\n",
      "Epoch 181/200\n",
      "423/423 - 0s - loss: 0.1053 - accuracy: 0.9693 - precision: 0.9738 - recall: 0.9669 - val_loss: 0.6199 - val_accuracy: 0.8652 - val_precision: 0.8832 - val_recall: 0.8582\n",
      "Epoch 182/200\n",
      "423/423 - 0s - loss: 0.0496 - accuracy: 0.9882 - precision: 0.9882 - recall: 0.9858 - val_loss: 0.6682 - val_accuracy: 0.8582 - val_precision: 0.8768 - val_recall: 0.8582\n",
      "Epoch 183/200\n",
      "423/423 - 0s - loss: 0.1197 - accuracy: 0.9669 - precision: 0.9692 - recall: 0.9669 - val_loss: 0.9488 - val_accuracy: 0.7447 - val_precision: 0.7445 - val_recall: 0.7234\n",
      "Epoch 184/200\n",
      "423/423 - 0s - loss: 0.1290 - accuracy: 0.9693 - precision: 0.9714 - recall: 0.9645 - val_loss: 0.5613 - val_accuracy: 0.8723 - val_precision: 0.8832 - val_recall: 0.8582\n",
      "Epoch 185/200\n",
      "423/423 - 0s - loss: 0.0277 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.5278 - val_accuracy: 0.8865 - val_precision: 0.8993 - val_recall: 0.8865\n",
      "Epoch 186/200\n",
      "423/423 - 0s - loss: 0.0627 - accuracy: 0.9835 - precision: 0.9835 - recall: 0.9835 - val_loss: 0.5662 - val_accuracy: 0.8723 - val_precision: 0.8777 - val_recall: 0.8652\n",
      "Epoch 187/200\n",
      "423/423 - 0s - loss: 0.1123 - accuracy: 0.9858 - precision: 0.9858 - recall: 0.9835 - val_loss: 0.5179 - val_accuracy: 0.8865 - val_precision: 0.8865 - val_recall: 0.8865\n",
      "Epoch 188/200\n",
      "423/423 - 0s - loss: 0.0055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.8723 - val_precision: 0.8786 - val_recall: 0.8723\n",
      "Epoch 189/200\n",
      "423/423 - 0s - loss: 0.0034 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6130 - val_accuracy: 0.8794 - val_precision: 0.8794 - val_recall: 0.8794\n",
      "Epoch 190/200\n",
      "423/423 - 0s - loss: 0.0024 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6538 - val_accuracy: 0.8723 - val_precision: 0.8786 - val_recall: 0.8723\n",
      "Epoch 191/200\n",
      "423/423 - 0s - loss: 0.3952 - accuracy: 0.9267 - precision: 0.9264 - recall: 0.9220 - val_loss: 0.8285 - val_accuracy: 0.8511 - val_precision: 0.8500 - val_recall: 0.8440\n",
      "Epoch 192/200\n",
      "423/423 - 0s - loss: 0.1410 - accuracy: 0.9669 - precision: 0.9713 - recall: 0.9598 - val_loss: 0.6057 - val_accuracy: 0.8582 - val_precision: 0.8705 - val_recall: 0.8582\n",
      "Epoch 193/200\n",
      "423/423 - 0s - loss: 0.0538 - accuracy: 0.9858 - precision: 0.9905 - recall: 0.9835 - val_loss: 0.8390 - val_accuracy: 0.8298 - val_precision: 0.8406 - val_recall: 0.8227\n",
      "Epoch 194/200\n",
      "423/423 - 0s - loss: 0.2296 - accuracy: 0.9409 - precision: 0.9499 - recall: 0.9409 - val_loss: 0.5944 - val_accuracy: 0.8865 - val_precision: 0.8905 - val_recall: 0.8652\n",
      "Epoch 195/200\n",
      "423/423 - 0s - loss: 0.3349 - accuracy: 0.9125 - precision: 0.9189 - recall: 0.9102 - val_loss: 0.5524 - val_accuracy: 0.8794 - val_precision: 0.8921 - val_recall: 0.8794\n",
      "Epoch 196/200\n",
      "423/423 - 0s - loss: 0.1330 - accuracy: 0.9645 - precision: 0.9668 - recall: 0.9645 - val_loss: 0.6287 - val_accuracy: 0.8582 - val_precision: 0.8643 - val_recall: 0.8582\n",
      "Epoch 197/200\n",
      "423/423 - 0s - loss: 0.0916 - accuracy: 0.9764 - precision: 0.9833 - recall: 0.9740 - val_loss: 0.6767 - val_accuracy: 0.8582 - val_precision: 0.8582 - val_recall: 0.8582\n",
      "Epoch 198/200\n",
      "423/423 - 0s - loss: 0.1268 - accuracy: 0.9622 - precision: 0.9620 - recall: 0.9574 - val_loss: 0.6547 - val_accuracy: 0.8582 - val_precision: 0.8571 - val_recall: 0.8511\n",
      "Epoch 199/200\n",
      "423/423 - 0s - loss: 0.0303 - accuracy: 0.9929 - precision: 0.9953 - recall: 0.9929 - val_loss: 0.6154 - val_accuracy: 0.8652 - val_precision: 0.8652 - val_recall: 0.8652\n",
      "Epoch 200/200\n",
      "423/423 - 0s - loss: 0.2268 - accuracy: 0.9574 - precision: 0.9596 - recall: 0.9551 - val_loss: 0.5886 - val_accuracy: 0.8652 - val_precision: 0.8652 - val_recall: 0.8652\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 40b8883a9e696402bc94cf72c8577928</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8936170339584351</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: RMSprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          246528    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 96)                86400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 498,444\n",
      "Trainable params: 498,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adagrad\n",
      "\n",
      "Train on 423 samples, validate on 141 samples\n",
      "Epoch 1/200\n",
      "423/423 - 6s - loss: 2.4562 - accuracy: 0.0898 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4354 - val_accuracy: 0.0993 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "423/423 - 0s - loss: 2.3899 - accuracy: 0.1348 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3490 - val_accuracy: 0.1348 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "423/423 - 0s - loss: 2.3424 - accuracy: 0.1655 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3174 - val_accuracy: 0.1631 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "423/423 - 0s - loss: 2.1845 - accuracy: 0.2175 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0224 - val_accuracy: 0.2270 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "423/423 - 0s - loss: 2.0215 - accuracy: 0.1986 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0318 - val_accuracy: 0.1915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "423/423 - 0s - loss: 1.9886 - accuracy: 0.1844 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8984 - val_accuracy: 0.2766 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "423/423 - 0s - loss: 2.1420 - accuracy: 0.1797 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8853 - val_accuracy: 0.2482 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "423/423 - 0s - loss: 1.9178 - accuracy: 0.2459 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1678 - val_accuracy: 0.1844 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "423/423 - 0s - loss: 1.9308 - accuracy: 0.2435 - precision: 0.5000 - recall: 0.0047 - val_loss: 1.8243 - val_accuracy: 0.3050 - val_precision: 0.5000 - val_recall: 0.0071\n",
      "Epoch 10/200\n",
      "423/423 - 0s - loss: 1.8485 - accuracy: 0.2482 - precision: 0.7500 - recall: 0.0142 - val_loss: 1.8359 - val_accuracy: 0.2837 - val_precision: 0.6667 - val_recall: 0.0142\n",
      "Epoch 11/200\n",
      "423/423 - 0s - loss: 1.8199 - accuracy: 0.2861 - precision: 0.6957 - recall: 0.0378 - val_loss: 1.9505 - val_accuracy: 0.1844 - val_precision: 0.5000 - val_recall: 0.0071\n",
      "Epoch 12/200\n",
      "423/423 - 0s - loss: 1.8374 - accuracy: 0.2766 - precision: 0.6957 - recall: 0.0378 - val_loss: 1.7685 - val_accuracy: 0.2979 - val_precision: 0.7500 - val_recall: 0.0213\n",
      "Epoch 13/200\n",
      "423/423 - 0s - loss: 1.7893 - accuracy: 0.3050 - precision: 0.6667 - recall: 0.0378 - val_loss: 1.7997 - val_accuracy: 0.2270 - val_precision: 0.5263 - val_recall: 0.0709\n",
      "Epoch 14/200\n",
      "423/423 - 0s - loss: 1.7847 - accuracy: 0.3215 - precision: 0.5946 - recall: 0.0520 - val_loss: 1.7288 - val_accuracy: 0.3333 - val_precision: 0.5714 - val_recall: 0.0284\n",
      "Epoch 15/200\n",
      "423/423 - 0s - loss: 1.7864 - accuracy: 0.3357 - precision: 0.5897 - recall: 0.0544 - val_loss: 1.7163 - val_accuracy: 0.3262 - val_precision: 0.5714 - val_recall: 0.0284\n",
      "Epoch 16/200\n",
      "423/423 - 0s - loss: 1.7334 - accuracy: 0.3215 - precision: 0.6111 - recall: 0.0520 - val_loss: 1.6616 - val_accuracy: 0.3617 - val_precision: 0.6154 - val_recall: 0.0567\n",
      "Epoch 17/200\n",
      "423/423 - 0s - loss: 1.7744 - accuracy: 0.3310 - precision: 0.6061 - recall: 0.0473 - val_loss: 1.7736 - val_accuracy: 0.2695 - val_precision: 0.6667 - val_recall: 0.0142\n",
      "Epoch 18/200\n",
      "423/423 - 0s - loss: 1.7418 - accuracy: 0.3215 - precision: 0.6923 - recall: 0.0426 - val_loss: 2.4335 - val_accuracy: 0.1206 - val_precision: 0.5000 - val_recall: 0.0071\n",
      "Epoch 19/200\n",
      "423/423 - 0s - loss: 1.7759 - accuracy: 0.3121 - precision: 0.6053 - recall: 0.0544 - val_loss: 1.6494 - val_accuracy: 0.3333 - val_precision: 0.5000 - val_recall: 0.0426\n",
      "Epoch 20/200\n",
      "423/423 - 0s - loss: 1.7190 - accuracy: 0.3357 - precision: 0.7027 - recall: 0.0615 - val_loss: 1.7550 - val_accuracy: 0.2695 - val_precision: 0.4333 - val_recall: 0.0922\n",
      "Epoch 21/200\n",
      "423/423 - 0s - loss: 1.7222 - accuracy: 0.3121 - precision: 0.5714 - recall: 0.0567 - val_loss: 1.6475 - val_accuracy: 0.3333 - val_precision: 0.8182 - val_recall: 0.0638\n",
      "Epoch 22/200\n",
      "423/423 - 0s - loss: 1.6889 - accuracy: 0.3404 - precision: 0.6800 - recall: 0.0804 - val_loss: 1.9329 - val_accuracy: 0.2482 - val_precision: 0.2857 - val_recall: 0.0142\n",
      "Epoch 23/200\n",
      "423/423 - 0s - loss: 1.6952 - accuracy: 0.3286 - precision: 0.6500 - recall: 0.0615 - val_loss: 1.5985 - val_accuracy: 0.3546 - val_precision: 0.7692 - val_recall: 0.0709\n",
      "Epoch 24/200\n",
      "423/423 - 0s - loss: 1.6648 - accuracy: 0.3452 - precision: 0.6222 - recall: 0.0662 - val_loss: 1.6312 - val_accuracy: 0.3333 - val_precision: 0.6250 - val_recall: 0.0709\n",
      "Epoch 25/200\n",
      "423/423 - 0s - loss: 1.7125 - accuracy: 0.3286 - precision: 0.7083 - recall: 0.0804 - val_loss: 1.8129 - val_accuracy: 0.3050 - val_precision: 0.5385 - val_recall: 0.0496\n",
      "Epoch 26/200\n",
      "423/423 - 0s - loss: 1.6720 - accuracy: 0.3452 - precision: 0.6500 - recall: 0.0615 - val_loss: 1.7323 - val_accuracy: 0.3475 - val_precision: 0.5385 - val_recall: 0.0496\n",
      "Epoch 27/200\n",
      "423/423 - 0s - loss: 1.6371 - accuracy: 0.3664 - precision: 0.7234 - recall: 0.0804 - val_loss: 1.6292 - val_accuracy: 0.3546 - val_precision: 0.6250 - val_recall: 0.0709\n",
      "Epoch 28/200\n",
      "423/423 - 0s - loss: 1.6174 - accuracy: 0.3759 - precision: 0.6379 - recall: 0.0875 - val_loss: 1.5915 - val_accuracy: 0.3404 - val_precision: 0.6250 - val_recall: 0.1064\n",
      "Epoch 29/200\n",
      "423/423 - 0s - loss: 1.5977 - accuracy: 0.4066 - precision: 0.6852 - recall: 0.0875 - val_loss: 1.6971 - val_accuracy: 0.3688 - val_precision: 0.7273 - val_recall: 0.1135\n",
      "Epoch 30/200\n",
      "423/423 - 0s - loss: 1.5962 - accuracy: 0.3877 - precision: 0.6866 - recall: 0.1087 - val_loss: 1.5132 - val_accuracy: 0.3972 - val_precision: 0.6316 - val_recall: 0.0851\n",
      "Epoch 31/200\n",
      "423/423 - 0s - loss: 1.5341 - accuracy: 0.4255 - precision: 0.6623 - recall: 0.1206 - val_loss: 1.5531 - val_accuracy: 0.4255 - val_precision: 0.6667 - val_recall: 0.0851\n",
      "Epoch 32/200\n",
      "423/423 - 0s - loss: 1.5016 - accuracy: 0.4397 - precision: 0.7857 - recall: 0.1040 - val_loss: 1.4357 - val_accuracy: 0.4397 - val_precision: 0.6400 - val_recall: 0.1135\n",
      "Epoch 33/200\n",
      "423/423 - 0s - loss: 1.5079 - accuracy: 0.4397 - precision: 0.7179 - recall: 0.1324 - val_loss: 1.3976 - val_accuracy: 0.4468 - val_precision: 0.7143 - val_recall: 0.1418\n",
      "Epoch 34/200\n",
      "423/423 - 0s - loss: 1.4389 - accuracy: 0.4634 - precision: 0.7045 - recall: 0.1466 - val_loss: 1.4871 - val_accuracy: 0.3617 - val_precision: 0.7037 - val_recall: 0.1348\n",
      "Epoch 35/200\n",
      "423/423 - 0s - loss: 1.5031 - accuracy: 0.4232 - precision: 0.6591 - recall: 0.1371 - val_loss: 1.4516 - val_accuracy: 0.3901 - val_precision: 0.6667 - val_recall: 0.1135\n",
      "Epoch 36/200\n",
      "423/423 - 0s - loss: 1.4281 - accuracy: 0.4563 - precision: 0.7195 - recall: 0.1395 - val_loss: 1.5983 - val_accuracy: 0.3972 - val_precision: 0.6053 - val_recall: 0.1631\n",
      "Epoch 37/200\n",
      "423/423 - 0s - loss: 1.4582 - accuracy: 0.4421 - precision: 0.6957 - recall: 0.1513 - val_loss: 1.4378 - val_accuracy: 0.4397 - val_precision: 0.7000 - val_recall: 0.1489\n",
      "Epoch 38/200\n",
      "423/423 - 0s - loss: 1.3582 - accuracy: 0.4988 - precision: 0.7303 - recall: 0.1537 - val_loss: 1.7318 - val_accuracy: 0.3333 - val_precision: 0.5882 - val_recall: 0.1418\n",
      "Epoch 39/200\n",
      "423/423 - 0s - loss: 1.4145 - accuracy: 0.4799 - precision: 0.7241 - recall: 0.1489 - val_loss: 1.3418 - val_accuracy: 0.4610 - val_precision: 0.6667 - val_recall: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "423/423 - 0s - loss: 1.3164 - accuracy: 0.5366 - precision: 0.7742 - recall: 0.1702 - val_loss: 1.3611 - val_accuracy: 0.4539 - val_precision: 0.7273 - val_recall: 0.1702\n",
      "Epoch 41/200\n",
      "423/423 - 0s - loss: 1.2942 - accuracy: 0.5272 - precision: 0.6860 - recall: 0.1962 - val_loss: 1.2760 - val_accuracy: 0.5319 - val_precision: 0.7209 - val_recall: 0.2199\n",
      "Epoch 42/200\n",
      "423/423 - 0s - loss: 1.2709 - accuracy: 0.5319 - precision: 0.7323 - recall: 0.2199 - val_loss: 2.1628 - val_accuracy: 0.3191 - val_precision: 0.5556 - val_recall: 0.1064\n",
      "Epoch 43/200\n",
      "423/423 - 0s - loss: 1.6130 - accuracy: 0.4184 - precision: 0.7300 - recall: 0.1726 - val_loss: 1.3618 - val_accuracy: 0.4681 - val_precision: 0.6970 - val_recall: 0.1631\n",
      "Epoch 44/200\n",
      "423/423 - 0s - loss: 1.2676 - accuracy: 0.5579 - precision: 0.7227 - recall: 0.2033 - val_loss: 1.2488 - val_accuracy: 0.5461 - val_precision: 0.7073 - val_recall: 0.2057\n",
      "Epoch 45/200\n",
      "423/423 - 0s - loss: 1.2079 - accuracy: 0.5697 - precision: 0.7879 - recall: 0.2459 - val_loss: 1.1898 - val_accuracy: 0.5674 - val_precision: 0.7250 - val_recall: 0.2057\n",
      "Epoch 46/200\n",
      "423/423 - 0s - loss: 1.2147 - accuracy: 0.5532 - precision: 0.7383 - recall: 0.2600 - val_loss: 1.6048 - val_accuracy: 0.4113 - val_precision: 0.5122 - val_recall: 0.1489\n",
      "Epoch 47/200\n",
      "423/423 - 0s - loss: 1.2807 - accuracy: 0.5296 - precision: 0.7230 - recall: 0.2530 - val_loss: 1.3541 - val_accuracy: 0.4539 - val_precision: 0.7027 - val_recall: 0.1844\n",
      "Epoch 48/200\n",
      "423/423 - 0s - loss: 1.1699 - accuracy: 0.5721 - precision: 0.7468 - recall: 0.2719 - val_loss: 1.2359 - val_accuracy: 0.5248 - val_precision: 0.7234 - val_recall: 0.2411\n",
      "Epoch 49/200\n",
      "423/423 - 0s - loss: 1.1568 - accuracy: 0.5697 - precision: 0.7791 - recall: 0.3168 - val_loss: 1.2296 - val_accuracy: 0.4965 - val_precision: 0.7544 - val_recall: 0.3050\n",
      "Epoch 50/200\n",
      "423/423 - 0s - loss: 1.1317 - accuracy: 0.5887 - precision: 0.7527 - recall: 0.3239 - val_loss: 1.2371 - val_accuracy: 0.5035 - val_precision: 0.7778 - val_recall: 0.2979\n",
      "Epoch 51/200\n",
      "423/423 - 0s - loss: 1.1215 - accuracy: 0.5816 - precision: 0.7598 - recall: 0.3664 - val_loss: 1.1092 - val_accuracy: 0.5887 - val_precision: 0.7538 - val_recall: 0.3475\n",
      "Epoch 52/200\n",
      "423/423 - 0s - loss: 1.0723 - accuracy: 0.5934 - precision: 0.7979 - recall: 0.3641 - val_loss: 1.4124 - val_accuracy: 0.4468 - val_precision: 0.5952 - val_recall: 0.3546\n",
      "Epoch 53/200\n",
      "423/423 - 0s - loss: 1.0652 - accuracy: 0.6028 - precision: 0.7619 - recall: 0.3783 - val_loss: 1.0867 - val_accuracy: 0.5957 - val_precision: 0.7973 - val_recall: 0.4184\n",
      "Epoch 54/200\n",
      "423/423 - 0s - loss: 1.0158 - accuracy: 0.6454 - precision: 0.7758 - recall: 0.4090 - val_loss: 1.1016 - val_accuracy: 0.5603 - val_precision: 0.7353 - val_recall: 0.3546\n",
      "Epoch 55/200\n",
      "423/423 - 0s - loss: 0.9886 - accuracy: 0.6312 - precision: 0.7817 - recall: 0.4232 - val_loss: 1.2601 - val_accuracy: 0.5319 - val_precision: 0.7843 - val_recall: 0.2837\n",
      "Epoch 56/200\n",
      "423/423 - 0s - loss: 1.0171 - accuracy: 0.6170 - precision: 0.7854 - recall: 0.4066 - val_loss: 1.1562 - val_accuracy: 0.5461 - val_precision: 0.7667 - val_recall: 0.3262\n",
      "Epoch 57/200\n",
      "423/423 - 0s - loss: 1.0249 - accuracy: 0.6170 - precision: 0.7321 - recall: 0.3877 - val_loss: 1.0176 - val_accuracy: 0.6099 - val_precision: 0.8065 - val_recall: 0.3546\n",
      "Epoch 58/200\n",
      "423/423 - 0s - loss: 0.9666 - accuracy: 0.6383 - precision: 0.8000 - recall: 0.4539 - val_loss: 0.9542 - val_accuracy: 0.6383 - val_precision: 0.8182 - val_recall: 0.4468\n",
      "Epoch 59/200\n",
      "423/423 - 0s - loss: 0.9245 - accuracy: 0.6643 - precision: 0.7815 - recall: 0.4397 - val_loss: 1.7314 - val_accuracy: 0.4043 - val_precision: 0.5667 - val_recall: 0.2411\n",
      "Epoch 60/200\n",
      "423/423 - 0s - loss: 1.1289 - accuracy: 0.5910 - precision: 0.7489 - recall: 0.3877 - val_loss: 1.1779 - val_accuracy: 0.5674 - val_precision: 0.6548 - val_recall: 0.3901\n",
      "Epoch 61/200\n",
      "423/423 - 0s - loss: 0.9865 - accuracy: 0.6383 - precision: 0.7647 - recall: 0.4303 - val_loss: 1.0904 - val_accuracy: 0.5887 - val_precision: 0.7229 - val_recall: 0.4255\n",
      "Epoch 62/200\n",
      "423/423 - 0s - loss: 0.9344 - accuracy: 0.6312 - precision: 0.7899 - recall: 0.4444 - val_loss: 1.3911 - val_accuracy: 0.4255 - val_precision: 0.5385 - val_recall: 0.3475\n",
      "Epoch 63/200\n",
      "423/423 - 0s - loss: 0.9464 - accuracy: 0.6359 - precision: 0.7764 - recall: 0.4350 - val_loss: 0.9757 - val_accuracy: 0.6383 - val_precision: 0.7561 - val_recall: 0.4397\n",
      "Epoch 64/200\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c81f9ed81028>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             )\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner  = RandomSearch(\n",
    "    build_model_lstm,     #Function to use search in... See different builds above\n",
    "    objective = \"val_accuracy\",  #Chooses \"best model\" looking for highest value of val_accuracy\n",
    "    max_trials = 30,       # Number of different combinations tried Nodes and layers\n",
    "    executions_per_trial = 1, \n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train,      #syntax just like in fit\n",
    "                y= y_train,\n",
    "            epochs=200,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val),\n",
    "            verbose=2\n",
    "            )\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "finished(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Hyperband\n",
    "Variation of RandomSearch http://jmlr.org/papers/volume18/16-558/16-558.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner  = Hyperband(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    hyperband_iterations=2,\n",
    "    max_epochs=150,\n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train, \n",
    "            y= y_train,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val))\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "finished(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laut Randomsearch bestes Model am 23.06.2020\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.LSTM(128, return_sequences=True,\n",
    "               input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(layers.LSTM(64, return_sequences=True)) \n",
    "model.add(layers.LSTM(96))  \n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=170,validation_data=(x_val,y_val),shuffle=False,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(layers.LSTM(256, return_sequences=True),\n",
    "                                        input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "model.add(layers.Bidirectional(layers.LSTM(192,return_sequences=True)))\n",
    "    \n",
    "model.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  optimizer='Adamax',\n",
    "                  metrics='accuracy') \n",
    "model.summary()\n",
    "#history=model.fit(x_train,y_train,epochs=170,validation_data=(x_val,y_val),shuffle=False,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tuner object into pickle file\n",
    "so it can be used in other scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"tuner_\"f\"{starttime}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best Trial from Tuner Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "bestmodel= tuner.hypermodel.build(best_hp)\n",
    "\n",
    "bestmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_chekpoints= \"tmp\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "tmp_chekpoints= \"C:\\\\ML\\\\checkpoints\\\\tmp\\\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "#csv_log = tf.keras.callbacks.CSVLogger(\"log.csv\", separator=',', append=False)\n",
    "csv_log = tf.keras.callbacks.CSVLogger(\"C:\\ML\\logs\\log.csv\", separator=',', append=False)\n",
    "\n",
    "#tb = tf.keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir='C:\\ML\\logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=20, verbose=0, mode='max', baseline=None, restore_best_weights=True)\n",
    "chk= tf.keras.callbacks.ModelCheckpoint(tmp_chekpoints, monitor='val_accuracy', verbose=0, save_best_only=False, save_weights_only=False, mode='max', save_freq='epoch')\n",
    "\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=200,batch_size=32, validation_data=(x_val,y_val),shuffle=False, verbose=2, callbacks=[csv_log, chk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training history of your LSTM models can be used to diagnose the behavior of your model.\n",
    "\n",
    "You can plot the performance of your model using the Matplotlib library. For example, you can plot training loss vs test loss as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.savefig(\"C:/ML/loss\"f\"{starttime}.png\")\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='lower right')\n",
    "pyplot.savefig(\"C:/ML/accuracy_\"f\"{starttime}.png\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfit Example\n",
    "Running this example produces a plot of train and validation loss showing the characteristic of an underfit model. In this case, performance may be improved by increasing the number of training epochs.\n",
    "\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model.png\" width=\"400\">\n",
    "\n",
    "\n",
    "Running this example shows the characteristic of an underfit model that appears under-provisioned.\n",
    "In this case, performance may be improved by increasing the capacity of the model, such as the number of memory cells in a hidden layer or number of hidden layers.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model-via-Status.png\" width=\"400\">\n",
    "\n",
    "#### Good Fit Example\n",
    "Running the example creates a line plot showing the train and validation loss meeting.\n",
    "Ideally, we would like to see model performance like this if possible, although this may not be possible on challenging problems with a lot of data.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-a-Good-Fit-for-a-Model.png\" width=\"400\">\n",
    "\n",
    "#### Overfit Example\n",
    "Running this example creates a plot showing the characteristic inflection point in validation loss of an overfit model.\n",
    "This may be a sign of too many training epochs.\n",
    "In this case, the model training could be stopped at the inflection point. Alternately, the number of training examples could be increased.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Overfit-Model.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('./tmp/epoch49-0.90-0.39.hdf5')\n",
    "\n",
    "\n",
    "#bestmodel.evaluate(x=x_test, y=y_test, verbose=2)\n",
    "model.evaluate(x=x_test, y=y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel.save(\"sign_lang_recognition_tuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor-gpu",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
